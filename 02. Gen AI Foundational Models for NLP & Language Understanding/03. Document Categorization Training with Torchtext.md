# Document Categorization Training with Torchtext

A neural network functions via matrix and vector operations called learnable parameters.
Here, you'll identify and obtain these parameters.
With networks having millions to trillions of parameters, Theta is used to collectively represent them.
![[Pasted image 20250306120021.png]]![[Pasted image 20250306120042.png|260]]

In neural network training, learnable parameters are fine tuned to enhance model performance.
This process is steered by the `loss` function, which serves as a measure of accuracy.
The goal is to find the optimal parameter values denoted as `Theta` that minimize the discrepancy between the model's predicted output `y hat` and the actual label `y`.
As your focus is solely on the parameters, you'll consider the loss function explicitly as a function of `Theta`.
Although the term `loss` and `costs` are often used interchangeably, for clarity, the terminology consistent with PyTorch's framework is followed.
![[Pasted image 20250306120318.png]]

The aim is to adjust `Theta` to lower loss and improve accuracy.
As the parameter `Theta` is adjusted, you'll observe a reduction in the loss, leading to an alignment between the true class labels `y` and the predicted labels `y hat`
Concurrently, there's an increase in the model's accuracy, which is a positive indicator of performance improvement.
## Cross entrop loss

Recall that you input an embedding vector into the network.
For each category, the neural network outputs a vector of logits, where each logit is a score reflecting the article's likelihood of fitting a particular news category as shown here.
Logits are transformed into probabilities through the `softmax` function depicted here.
This process, given input x, computes the probability that the predicted class `y hat` corresponds to a certain category.
Each logit is exponentiated to ensure positivity and then normalized against the sum of all logits.
This creates a conditional distribution for each predicted class.
The `softmax` transformation plays a crucial role in enhancing the distinction between scores assigned to different classes.
![[Pasted image 20250306122003.png|400]]

Let's begin by evaluating the expected value difference between the true distribution, that is the probability of y, and the conditional distribution, that is the probability of y given x and Theta.
![[Pasted image 20250306122531.png|500]]

Rather than simply calculating the difference and squaring it, apply the logarithm to both distributions before finding their difference known as the `KL divergence`.
![[Pasted image 20250306122659.png|500]]

Only the second term, which is referred to as cross-entropy loss, is dependent on Theta.
![[Pasted image 20250306123432.png]]

The problem now is finding the distribution of y, for which you can employ a useful technique.
![[Pasted image 20250306123607.png]]

You can compute the expected value of a function using the distribution, the probability of z, depicted here.
![[Pasted image 20250306125321.png]]

However, if the distribution is unknown, you can estimate it by averaging the function applied to a set of samples.
This technique is known as `Monte Carlo sampling`.
![[Pasted image 20250306125406.png]]

Monte Carlo sampling can be applied to approximate the true cross-entropy loss by averaging the output of a function over samples x and y as shown here.
![[Pasted image 20250306130159.png]]

You can calculate the conditional distribution using the softmax function.
It should be noted that usually the batches of data have been used, but not all the samples.
![[Pasted image 20250306130252.png]]

In PyTorch, the loss function utilizes the network's output logit z, which is a proxy for `y hat` and the true labels y for computation.
![[Pasted image 20250306130356.png]]
### Cross entropy in PyTorch

```python
from tourch.nn import CrossEntropyLoss

model = TextClassificationModel(vocab_size, emsize, num_class)
criterion = CrossEntropyLoss()
predicted_label = model(text, offsets)
loss = criterion(predicted_label, label)
```

## Optimization
Now you are going to do optimization, which is the method used to minimize the loss.
The gradient descent equation is key to reducing loss in the model.
Here's the breakdown.
To update your next parameter to `Theta_k + 1` from `Theta_k` using the current parameter values nudging closer to minimal loss, the learning rate `Eta` sets your step size.
The gradient of the loss function points where the loss changes most.
By moving in the reverse direction of this gradient, you can fine tune your parameters, thereby decreasing the loss with each step.
![[Pasted image 20250306134730.png|500]]

Gradient descent starts with an initial random parameter guess denoted as k equals zero.
In the first iteration, that is k equals one, adjust parameters using the gradient of the loss function scaled by a learning rate of 0.1 and add this to the parameters from k equals zero to compute the loss.
![[Pasted image 20250306135316.png|300]]

This process is repeated for k equals two, updating the parameters and recalculating the loss, which decreases incrementally.
This iterative refinement continues, reducing loss and enhancing model accuracy with each step.
This image depicts a 2D loss function surface with a chosen starting point.
The algorithm fine tunes the parameters iteratively toward the minimum loss visualized by the red point moving downward along the white trajectory line that converges on the lowest loss point.
![[Pasted image 20250306135628.png|400]]

In practical use, neural networks have millions of parameters, leading to a complex loss surface as shown here.
Loss can vary sharply, rising or falling quickly.
Many strategies exist to reduce loss, known as optimization methods.
These strategies will not be detailed here, but will be referred to as methods to improve optimization or training.
![[Pasted image 20250306135755.png|400]]

Typically, you partition your data set into three subsets: training data for learning, validation data for hyperparameter tuning, and test data to evaluate real-world performance.
![[Pasted image 20250306135834.png|300]]

### Optimization in PyTorch

In PyTorch, you will first initialize the stochastic gradient descent or SGD optimizer for the model's parameters with a learning rate, or LR, of 0.1.
A scheduler reduces the learning rate by a factor of Gamma after each epoch, which enhances the optimization process.
Reset all gradients for the variables to be updated, that is the learnable weights of the model, to zero before the next iteration.
```python
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)
optimizer.zero_grad()
```

The model makes a prediction and calculates the loss.
The backward function computes the derivatives of the loss.
Finally, gradient clipping is applied to improve optimization.
```python
predicted_label = model(text, offsets)

loss = criterion(predicted_label, label)

loss.backward()

torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)
optimizer.step()
```

## Recap

- Neural network functions via matrix and vector operations called learnable parameters.
- In neural network training
	- learnable parameters are fine tuned to enhance model performance.
	- This process is steered by the loss function, which serves as a measure of accuracy.
- The prediction function
	- Works on real text that starts by taking in tokenized text.
	- Processes the text through the pipeline and the model predicts the category.
- Cross-entropy is used to find the best parameters.
- For unknown distribution, estimate it by averaging the function applied to a set of samples. This technique is known as Monte Carlo sampling.
- Optimization is used to minimize the loss.
- Generally, the data set should be partitioned into three subsets: `training data` for learning, `validation data` for hyperparameter tuning, and `test data` to evaluate real-world performance.