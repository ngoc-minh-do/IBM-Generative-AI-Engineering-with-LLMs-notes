# Data Loaders

A data loader helps you prepare and load data, leading frameworks such as PyTorch have a dedicated `DataLoader` class that you can use to handle and prepare data while training generative AI models. Using data loaders, you can output data in batches instead of one sample at a time.

## Purpose of using NLP data loaders
- PyTorch enable efficient loading and pre-processing of textual data for NLP tasks. 
- Data loaders enable efficient batching and shuffling of data which is essential for training neural networks. 
- Allow for on-the-fly pre-processing, which optimizes memory usage by loading only the required data during training. 
- Seamlessly integrate with the PyTorch training pipeline, making it easier to train and evaluate models. 
- Simplify data augmentation and pre-processing, allowing you to apply various transformations to the input data. 

## Custom Dataset

```python
from torch.utils.data import Dataset

sentences = [
    "If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.",
    "Fame's a fickle friend, Harry.",
    "It is our choices, Harry, that show what we truly are, far more than our abilities.",
    "Soon we must all face the choice between what is right and what is easy.",
    "Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.",
    "You are awesome!"
]

# Define a custom dataset
class CustomDataset(Dataset):
    def __init__(self, sentences):
        self.sentences = sentences

    def __len__(self):
        return len(self.sentences)

    def __getitem__(self, idx):
        return self.sentences[idx]

# Create an instance of your custom dataset
custom_dataset = CustomDataset(sentences)

# Define batch size
batch_size = 2

# Create a DataLoader
dataloader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=True)

# Iterate through the DataLoader
for batch in dataloader:
    print(batch)
```

An iterator is an object that can be looped over, it contains elements that can be iterated through. 
You commonly use iterators to traverse large datasets. 
Each time you call the next function, it returns new batches of samples. 
```python
data_iter = iter(dataloader)
next(data_iter)
```

## Transformation on input text data
In most NLP applications, the majority of data transformation is performed in the batch function. 
These transformations include:
- Tokenizing
- Numericalizing
- Resizing it to a consistent size
- Converting it into tensors

Tokenization and vocabulary building
```python
tokenizer = get_tokenizer("basic_english")
vocab = build_vocab_from_iterator(map(tokenizer, sentences))
```

Handle variable-length data
```python
from torch.nn.utils.rnn import pad_sequence
for batch in dataloader:
	padded_batch = pad_sequence(batch, batch_first=True, padding_value=0)
```
- `batch_first`: indicate first dimension in the output tensor is batch dimension. Tensor size = (`<batch size>`, `<sequence size>`)

## `Collate` function

To keep the original dataset untouched, you can take care of data transformation in the `collate` function. 
```python
# Create a custom collate function
def collate_fn(batch):
    # Tokenize each sample in the batch using the specified tokenizer
    tensor_batch = []
    for sample in batch:
        tokens = tokenizer(sample)
        # Convert tokens to vocabulary indices and create a tensor for each sample
        tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))

    # Pad sequences within the batch to have equal lengths using pad_sequence
    # batch_first=True ensures that the tensors have shape (batch_size, max_sequence_length)
    padded_batch = pad_sequence(tensor_batch, batch_first=True)
    
    # Return the padded batch
    return padded_batch
```
