# Reward Modeling: Response Evaluation
## Learning objective
- Define reward modeling 
- Describe response evaluation

## Reward Modeling
The reward evaluates the degree of alignment, meaning a model responds to human preferences.
- Reward modeling quantifies the response quality by assigning numerical values to responses for assessing and comparing performance.
- It also guides model optimization by optimizing parameters to maximize the assigned score and improve the model's performance.
- Reward modeling incorporates user preferences in the scoring function for customizing model behavior.
- It ensures consistency and reliability, providing a consistent and reliable evaluation of the responses.

## Response evaluation
Let's understand response evaluation.
To evaluate the responses of causal decoder, such as chatbots, let's use a reward function based on user preferences, shown as a purple box.
Training a reward function assigns high rewards to responses such as cats.
For example, insert a query for LLM to ensure that the large language model or LLM prefers cats.
LLM1 likes cats and LLM2 thinks cats are just ok.
![[Pasted image 20250330230533.png|400]]

The reward function evaluates the query and provides the scores.
The score should be high to ensure the response aligns with the LLMs preference.
Here, the LLM likes cats.
Therefore, reward function assigns high scores to responses that reflect the preference for cats.
![[Pasted image 20250330230608.png|500]]

Repeat the process for LLM2 because it thinks that cats are just ok.
![[Pasted image 20250330230626.png|500]]

Lets consider a scoring function that assigns higher scores to generate precise and contextually accurate answers.
For example, the query is `which country owns Antarctica?` To create a response, lets input this query into two chatbots A and B.
Response A states that `Antarctica is governed by the Antarctic Treaty System`, which is factual and accurate.
In contrast, response B claims that `penguin overlords run the showdown there`, which is an assumption and not factually correct.
Therefore, the goal is to select response A to prioritize the factual accuracy of the response based on the user preferences.

To input the query and response into the scoring function, first, tokenize the user input query where the omega symbol w with a subscript indicating sequence index denoted by each token.
![[Pasted image 20250330230846.png|500]]

Next, tokenize response A and denote it with the variable omega hat A representing it's an estimation.
![[Pasted image 20250330230914.png|500]]

Now tokenize response B and denote it as variable omega hat B representing it as an estimation.
Here, sequences need not be of the same length.
![[Pasted image 20250330230933.png|500]]

The scoring function takes the query and appends the chatbots responses.
It means the tokens are collected and inserted into the scoring function denoted by r.
The screen displays the query in white and the response in blue.
![[Pasted image 20250330231046.png|500]]

Next, use the omega notation.
Denote the query as omega and the response as omega hat.
Therefore, response A is good with a score of 0.89.
This scoring process evaluates the response quality based on the accuracy and relevance of the query.
![[Pasted image 20250330231105.png|500]]

Similarly, the scoring function displays the query and bad response in red.
![[Pasted image 20250330231130.png|500]]

Upon using omega notation, the omega represents the query and the response as omega hat B.
Therefore, response B is bad with a score of 0.03.
This scoring reflects the users preferences based on the training data.
For example, response B may receive a higher score by training the scoring function to prioritize assumption.
![[Pasted image 20250330231154.png|500]]

## Recap
- The reward model takes prompt as an input and responds as an output regarding reward or score.
- Reward modeling helps
	- quantifying quality responses
	- guiding model optimization 
	- incorporating reward preferences
	- ensuring consistency andreliability of the responses.
- The scoring function
	- Use two inputs to select the factual and contextual response in the response evaluation process.
	- Based on the generated responses, you'll get scores or rewards for the response.
	- The scoring function takes the query and appends the chatbots responses.
