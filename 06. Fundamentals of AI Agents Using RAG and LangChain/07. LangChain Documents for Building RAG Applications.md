# LangChain Documents for Building RAG Applications

## Learning objective
- Explore LangChain tool documents to build RAG applications.
- Explain the components of documents such as the document object, document loader, text splitter, vector database, and retriever.

## Introduction to building applications
Building applications rely on AI technologies to understand how to build and implement LLM-based applications.
LangChain simplifies the application-building process by providing an easy-to-use interface for integrating data APIs and pre-trained language models.
For building applications, it is vital to collect relevant documents.
![[Pasted image 20250405211459.png]]

## Documents
Let's delve into LangChain documents.
LLM applications incorporate user-specific data that doesn't require initial training.
Retrieval augmented generation, or RAG, played an important role in achieving this.
In RAG, the external data is retrieved and then integrated during the next steps.
Additionally, LangChain facilitates comprehensive tools for RAG applications, focusing on the retrieval step to ensure sufficient data fetching.
The data fetching process includes various steps such as document source, document loaders, document split, document embeddings, document storage, and document retrieval.
![[Pasted image 20250405211547.png]]

## Documents source
The document source in LangChain serves as a container for data information using key attributes.
These attributes are the page_content attribute, which holds document content limited to strings, and the metadata attribute stores arbitrary data associated with the document.

For example document_id, file name, and other relevant details.
These attributes allow the document object to manage and use document data within LangChain.
```python
from langchain_core.documents import Document

Document(page_content="""Python is an interpreted high-level general-purpose programming language. 
                        Python's design philosophy emphasizes code readability with its notable use of significant indentation.""",
         metadata={
             'my_document_id' : 234234,
             'my_document_source' : "About Python",
             'my_document_create_time' : 1680013019
         })
```

## Document loader
For the RAG application, loading documents is a vital process.
LangChain loads documents from more than 100 sources, including major providers such as Airbyte and unstructured.
It handles various document types including HTML, PDF and code from various locations such as S3 buckets and public websites.

For example, the web-based loader imports text content directly from websites or URLs.
```python
loader = WebBaseLoader("https://python.langchain.com/v0.2/docs/introduction/")
web_data = loader.load()
```

## Document transformation: Text splitter
The next is the document transformation step where data gets split into chunks.
LangChain retrieves relevant isolated sections from the documents by splitting large documents into manageable pieces with tailored text splitters.

For example, the recursive CharacterTextSplitter recursively splits the text and the markdown header text_splitter uses markdown headers to divide text.
Let's use character text splitter with a user-defined separator to view the number of chunks the content has been split into.
```python
text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20, separator="\n")  # define chunk_size which is length of characters, and also separator.
chunks = text_splitter.split_documents(document)
print(len(chunks))
```

## Document embeddings
Next is creating embeddings for documents.
Embeddings capture the semantic meaning of the text.

For example, let's use an embedding model from watsonx.ai.
The embeddings have become increasingly important.
```python
from langchain_ibm import WatsonxEmbeddings
from ibm_watsonx_ai.metanames import EmbedTextParamsMetaNames

embed_params = {
    EmbedTextParamsMetaNames.TRUNCATE_INPUT_TOKENS: 3,
    EmbedTextParamsMetaNames.RETURN_OPTIONS: {"input_text": True},
}

watsonx_embedding = WatsonxEmbeddings(
    model_id="ibm/slate-125m-english-rtrvr",
    url="https://us-south.ml.cloud.ibm.com",
    project_id="skills-network",
    params=embed_params,
)

texts = [text.page_content for text in chunks]

embedding_result = watsonx_embedding.embed_documents(texts)
embedding_result[0][:5]
```

## Document storage: Vector database
Theres a growing need for databases to store data efficiently.
For example, let's use the Chromavector database to store embeddings and perform a similarity search to retrieve relevant content for the inserted query.
You can view the content that the LLM has retrieved from the query by calculating the distance and finding the nearest text chunk embedding.
```python
from langchain.vectorstores import Chroma

docsearch = Chroma.from_documents(chunks, watsonx_embedding)

query = "Langchain"
docs = docsearch.similarity_search(query)
print(docs[0].page_content)
```
![[Pasted image 20250405212231.png]]

## Document retriever
It is important to retrieve data efficiently once it is stored in a vector database.
LangChain supports various retrieval algorithms tailored to enhance search effectiveness.
LangChain facilitates various retrievers such as vector store retriever for similarity searches, the parent document retriever for searching within the document chunks, and the self-query retriever for separating.
Let's identify relevant information for LangChain using vector store retriever for the document.
Here is an example of the response.
You can see that it shows a similar result as the similarity search strategy to search in a vector database because the vector store retriever is based on similarity.
```python
retriever = docsearch.as_retriever()
docs = retriever.invoke("Langchain")
docs[0].page_content
```
![[Pasted image 20250405212338.png]]
## Recap
- LangChain facilitates comprehensive tools for RAG applications, focusing on their retrieval step to ensure sufficient data fetching.
- The document object in LangChain serves as a container for data information, including two key attributes such as page content and metadata.
- LangChain document loader handles various document types such as HTML, PDF and code from various locations.
- LangChain in document retrieves relevant isolated sections from documents by splitting them into manageable pieces.
- Embedding model embeds documents and LangChain facilitates various retrievers.
