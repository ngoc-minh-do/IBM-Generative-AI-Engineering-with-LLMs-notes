# Advanced Methods of Prompt Engineering

## Learning objective
- Apply advanced methods of prompt engineering to enhance prompt design.
- Discuss the effective implementation of the tools and applications of prompt engineering to real world scenarios.

## Zero-shot prompt
This type of prompt instructs an LLM to perform a task without any prior specific training or examples.
Here, the LLM is asked to classify a statement as true or false.
	`The Eiffel Tower is located in Berlin.`
Then the model gives the response.
This task requires the LLM to understand the context and information without any previous tuning for the specific query.
![[Pasted image 20250405172800.png]]
## A one-shot prompt
A one-shot prompt gives the LLM a single example to help it perform a similar task.
For example, 
	`How is the weather today?`
The LLM shows how to translate a sentence from English to French.
This serves as a template.
Then it's given a new sentence
	`where is the nearest supermarket`
 and is expected to translate it into French using the learned format.
The AI uses the initial example to correctly perform the new translation.
![[Pasted image 20250405173010.png]]
## Few-shot prompt
Another method is few-shot prompting where the AI learns from a small set of examples before tackling a similar task.
This helps the AI generalize from a few instances to new data.
For example, the LLM is shown three statements, each labeled with an emotion.
These examples teach the LLM to classify emotions based on context.
Then it classifies a new statement.
	`That movie was so scary. I had to cover my eyes.`
The LLM will output the emotion.
![[Pasted image 20250405173200.png]]

## Chain-of-thought (CoT) prompting
- Chain-of-thought or COT prompting is a technique used to guide LLM through complex reasoning step-by-step.
- This method is highly effective for problems requiring multiple intermediate steps or reasoning that mimics human thought processes.
![[Pasted image 20250405173239.png]]

The example shows how CoT prompting is applied to an arithmetic problem.
The prompt asks the model to consider the problem of a store that initially had 22 apples, sold 15, and then received a new delivery of eight apples.
The task is to determine how many apples there are now.
![[Pasted image 20250405173322.png]]

You can view the model output for the CoT prompt query by breaking down the calculation into clear sequential steps.
The model arrives at the correct answer and provides a transparent explanation.
![[Pasted image 20250405173338.png]]

## Self-consistency
- Self-consistency is a technique for enhancing the reliability and accuracy of outputs.
- It involves generating multiple independent answers to the same question and then evaluating these to determine the most consistent result.
![[Pasted image 20250405173515.png]]

In this example, you see a problem involving age calculation.
The query is: 
	`When I was six, my sister was half my age. Now I am 70. What age is my sister? `
The model is prompted to produce three independent calculations and explanations to ensure accuracy.
![[Pasted image 20250405173634.png]]

You can view the model outputs with three different ways of calculation and determine a consistent answer.
This approach demonstrates how self-consistency can verify the reliability of the responses from LLMs by cross-verifying multiple paths to the same answer.
![[Pasted image 20250405173648.png]]

## Tools and applications
Next, let's explore the tools and applications used in prompt engineering.
Certain tools can facilitate interactions with LLMs, such as OpenAI's Playground, LangChain, Hugging Face's Model Hub, and IBM's AI Classroom.
- They allow you to develop, experiment with, evaluate, and deploy prompt.
- They enable real-time tweaking and testing of prompt to see immediate effect on outputs.
- Moreover, they provide access to various pre-trained models suitable for different tasks and languages.
- They also facilitate the sharing and collaborative editing of prompts among teams or communities.
- Finally, they offer tools to track changes, analyze results, and optimize prompt based on performance metrics.
![[Pasted image 20250405173744.png]]

## Prompt template
Let's learn more about LangChain, a tool for prompt engineering.
LangChain uses prompt templates, predefined recipes for generating effective prompt for LLMs.
These templates include 
-  instructions for the language model
- a few-shot examples to help the model understand contexts and expected responses, 
- a specific question directed at the language model.
![[Pasted image 20250405173847.png]]

Here is a code snippet to apply a prompt template from LangChain.
First, import the prompt template from LangChain core prompts.
Then define a joke prompt template, `tell me a joke about`.
This template has placeholders for an adjective and the content.
```python
from langchain_core.prompts import PromptTemplate

prompt_template = PromptTemplate.from_template(
	"Tell me a {adjective} joke abount {content}."
)
```

To use the template, call prompt template format with specific values funny for the adjective and chickens for the content.
```python
prompt_template.format(adjective="funny", content="chickens")
```

This generates the prompt, `tell me a funny joke about chickens`.
This approach simplifies prompt creation, making prompt consistent and adaptable to different contexts.

## Applications
In prompt applications, an agent is a crucial concept.
Powered by LLMs and integrated tools like LangChain, agents perform complex tasks across various domains using different prompts.
![[Pasted image 20250405180841.png]]

Transformative applications include 
- Q&A agents with sources
- content agents for creation and summarization
- analytic agents for data analysis and business intelligence
- and multilingual agents for seamless context aware translation and communication.
![[Pasted image 20250405180911.png]]
## Recap
- Advanced methods for prompt engineering include zero-shot prompt, few-shot prompt, chain-of-thought prompting, and self-consistency.
- Prompt engineering tools can facilitate interactions with LLMs.
- LangChain uses `prompt templates` to generate effective prompts.
- In prompt applications, an agent can perform complex tasks across domains using different prompts.