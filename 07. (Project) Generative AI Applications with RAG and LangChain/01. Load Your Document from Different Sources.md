# Load Your Document from Different Sources

## Learning objective
- Describe how LangChain uses document loaders to simplify data integration by allowing you to import data from various sources efficiently.
- Explain how to load different types of files, including text, PDF, Markdown, JSON, CSV, and Doc X.
- Discuss how to load content directly from websites and handle unstructured files.

## Document loaders and LangChain
- LangChain uses document loaders to gather information from several sources such as websites, files, and databases, and then prepares it for further use.
- Document loaders, act as connectors, pulling in data, and converting it into a format LangChain can work with.
![[Pasted image 20250405224954.png]]

- Collecting the necessary information is the first step in creating a retrieval augmented generation or rag application.
- Once you have the data, you can start processing it to find relevant answers based on user queries.
- This process helps your application access and use a wide range of information efficiently.
![[Pasted image 20250405225024.png]]

## Load text
If you're working with plain text files, you can utilize the text loader class and LangChain to load them efficiently.
LangChain features a load method explicitly designed for loading data as documents from configured sources.
The code here demonstrates how to use this method to load text data.
After loading each document object, which includes metadata and page content attributes is stored in a list.
```python
from langchain_community.document_loaders import TextLoader

loader = TextLoader("new-Policies.txt")
data = loader.load()

print(data[0])
```

Here is an example where the content from a text file is printed to illustrate how document objects are structured and accessed.
![[Pasted image 20250405225613.png]]

## Load PDF
For PDF files, the PyPDFLoader class in LangChain is your go-to tool.
This class can load a PDF into an array of document objects with each document capturing the content of a page along with metadata and page number.
```python
from langchain_community.document_loaders import PyPDFLoader

loader = PyPDFLoader("path_to_pdf.pdf")
data = loader.load()

# Display the first page of the PDF
print(data[0])
```
You can see here that the PDF file of an academic paper has been loaded.
This is the content of the first page.
![[Pasted image 20250405225811.png]]

You can also use the PyMuPDFLoader, the fastest PDF parsing tool in LangChain.
This loader processes each page quickly and provides detailed metadata about the PDF and its pages, returning one document object per page.
```python
from langchain_community.document_loaders import PyMuPDFLoader

loader = PyMuPDFLoader("path_to_pdf.pdf")
data = loader.load_and_split()

# Display the first page of the PDF
print(data[0])
```

Let's revisit the paper loaded in the previous slide using this loader.
The critical difference between PyMuPDFLoader and PyPDFLoader is that it includes more comprehensive metadata.
![[Pasted image 20250405225939.png]]

## Load Markdown
If you are working with a markdown file, LangChain offers unstructured markdown loader class to load it.
```python
from langchain_community.document_loaders import UnstructuredMarkdownLoader

markdown_path = "markdown-sample.md"
loader = UnstructuredMarkdownLoader(markdown_path)

data = loader.load()

data
```

Note that the content can include a lot of line-break characters.
![[Pasted image 20250405230119.png]]

## Load JSON
When working with JSON files, consider their unique key value pair structures.
```python
import json
from pathlib import Path

file_path = 'path_to_json.json'
data = json.loads(Path(file_path).read_text())
```

Let's see an example.
Let's use this code to load and display a JSON file.
Here is the file.
![[Pasted image 20250405230300.png]]

It is structured with various fields, and you specifically want to extract the content field from messages for further processing in LangChain.
How will you do it? LangChain offers the JSON loader class specifically designed to load JSON files.
This loader utilizes a JQ schema to parse JSON files according to specific needs.
For example, if you want to extract values from the content field under the messages key in your JSON data, you should define an appropriate JQ schema for content.
```python
from langchain_community.document_loaders import JSONLoader

file_path = 'path_to_json.json'

loader = JSONLoader(
    file_path=file_path,
    jq_schema='.messages[].content',
    text_content=False)

data = loader.load()
data
```

One set, the loader will extract these values and load them into an array of document objects where each document represents one piece of message content.
![[Pasted image 20250405230526.png]]

## Load CSV
When dealing with data in CSV files, the CSV loader and LangChain is the ideal tool.
This loader is designed to handle CSV files by converting each row of data into a separate document object.
```python
from langchain_community.document_loaders.csv_loader import CSVLoader

loader = CSVLoader(
    file_path="path_to_csv.csv"
)
data = loader.load()
data
```

Here's an example.
![[Pasted image 20250405230649.png]]

If you want to load the data, all in one document object, you can use unstructured CSV loader.
```python
from langchain_community.document_loaders.csv_loader import UnstructuredCSVLoader

loader = UnstructuredCSVLoader(
    file_path="path_to_csv.csv", mode="elements"
)
data = loader.load()
data[0].page_content
```

Unlike CSV loader, which treats each row as a separate document with headers defining the data, unstructured CSV loader's entire CSV file is considered a single unstructured table element.
This is useful when analyzing the data as a table rather than individual entries.
![[Pasted image 20250405230828.png]]

## Load website
If you need to load and parse an online web page, the standard method is to use a Python package called Beautiful Soup.
For example, here is a website you want to load.
Here is the web URL and a screenshot of a part of the web.
![[Pasted image 20250405230951.png]]
You can use the code shown here to load and parse it using Beautiful Soup.
Let's look at its performance.
```python
import requests
from bs4 import BeautifulSoup

url = 'https://www.ibm.com/topics/langchain'
response = requests.get(url)

soup = BeautifulSoup(response.content, 'html.parser')
print(soup.prettify())
```


Here is a screenshot of part of the loading response.
You can see that Beautiful Soup loads the web content and includes several HTML tags and external links, which are unnecessary and even a burden if you want to load the web's text content.
Beautiful Soup has its limitations.
![[Pasted image 20250405231028.png]]

Is there a better method? Yes.
The WebBaseLoader and LangChain is designed to efficiently extract all text from HTML web pages and convert it into a document format suitable for downstream processing.
Let's load the same URL using WebBaseLoader again here.
```python
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader("https://www.ibm.com/topics/langchain")

data = loader.load()
data
```
Once loaded, observed that the loader only captures all text from the web page, avoiding HTML tags and links, and just including line break characters.
![[Pasted image 20250405231204.png]]

What do you do when multiple websites need to load? You can create a list of these websites and pass it onto the web-based loader.
The loader will load all the content of each website into a document object and format them into an array.
```python
from langchain_community.document_loaders import WebBaseLoader

loader = WebBaseLoader([
	"https://www.ibm.com/topics/langchain",
	"...",
])

data = loader.load()
data
```
![[Pasted image 20250405231338.png]]

## Load Word
LangChain also provides `Docx2txtLoader` to help load a word `.docx` file to document content similar to text loader.
```python
from langchain_community.document_loaders import Docx2txtLoader

loader = Docx2txtLoader("file-sample.docx")
data = loader.load()
data
```
Here is an example of how to load a Word document.
![[Pasted image 20250405231513.png]]

## UnstructuredFileLoader
For projects requiring flexibility due to unknown or varied file formats, the unstructured file loader in LangChain works perfectly.
This loader is designed for general-purpose use and supports many file types, including text files, PowerPoint presentations, HTML pages, PDFs, images, and more.
For instance, if you have a markdown file and a text file to load, you can use just this one loader.
```python
from langchain_community.document_loaders import Docx2txtLoader

files = ["path_to_markdown.md", "path_to_txt.txt"]
loader = UnstructuredFileLoader(files)
data = loader.load()
data
```
The unstructured file loader efficiently converts the content of these diverse files into a single document object.
![[Pasted image 20250405231728.png]]
## Recap
- LangChain uses document loaders that are connectors that gather data and convert it into a compatible format.
- TextLoader class and LangChain to load plain text files.
- PyPDFLoader class and LangChain or the PyMuPDFLoader is ideal for PDF files.
- For a markdown file, LangChain offers UnstructuredMarkdownLoader.
- LangChain offers the JSONLoader class, which is designed to load JSON files.
- The CSVLoader in LangChain is the ideal tool for dealing with data and CSV files.
- To load and parse an online web page, use the Python package, BeautifulSoup or the WebBaseLoader in LangChain, to load multiple websites, use WebBaseLoader.
- Finally, you learned that the UnstructuredFileLoader in LangChain is an ideal solution for projects with unknown or varied file formats.