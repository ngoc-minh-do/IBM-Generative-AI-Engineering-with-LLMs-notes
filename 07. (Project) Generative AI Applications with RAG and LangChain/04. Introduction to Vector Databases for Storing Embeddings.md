# Introduction to Vector Databases for Storing Embeddings

## Learning objective
- Describe how to store embeddings using a vector store.
- Explain how Chroma DB, a vector database supported by LangChain can be used to save embeddings.
- Discuss how to conduct a similarity search within a vector database to retrieve the most relevant content that matches the query.

## How a vector store works
Once you know how to load, split and embed data from various sources to prepare it for downstream tasks and have the embeddings of your data sources.
The next crucial step is storing them.
You can achieve this using a vector store specifically designed to store embeddings.
A vector database does more than just store data.
It also retrieves the required information based on queries using a similarity search.
Here's how it works.
The query is first converted into embeddings and then input into the vector database.
The database performs similarity calculations to search for and retrieve the most relevant content that matches the query.
![[Pasted image 20250406125603.png]]

Vector databases are essential because embeddings convert data.
Often unstructured data like text into numerical vector formats within a high-dimensional space.
Traditional databases like SQL are not optimized for storing and querying extensive vectoring data and often struggle with effectively storing and searching for these vector representations.
Vector stores, on the other hand, can index and quickly search for similar vectors using sophisticated similarity algorithms.
This capability allows applications to find related vectors based on a target vector query enabling efficient and effective information retrieval.
![[Pasted image 20250406125647.png]]

## Chroma DB using LangChain
Let's explore a vector database supported by LangChain called Chroma DB.
Chroma DB is an open source vector store for storing and retrieving vector embeddings.
Its primary use is to save embeddings and metadata, which large language models can utilize later.
Additionally, it's a powerful tool for semantic search engines over text data.
Let's take a look at how to implement Chroma DB using code.
Before constructing a vector database, assume you have loaded and split your target data into chunks.
Additionally, it would be the best to have an embedding model object ready.
In this example, an embedding model has been constructed using watsonx.
![[Pasted image 20250406125736.png]]

Constructing the Chroma DB vector database is straightforward.
First, you import the Chroma class from LangChain vector stores.
Then using this Chroma class, you called the chunks an embedding model.
Chroma DB will handle the rest automatically, making the process seamless and efficient.
![[Pasted image 20250406125835.png]]

## Similarity search
Here, you can see a similarity search within a vector database.
The process starts with a query, which could be any question text you're interested in.
The embedding model converts this query into a numerical vector format, transforming it to a high-dimensional vector that the vector database can process.
The vector database contains numerous pre stored vectors related to the source data.
When the embedded query enters the database, the system performs similarity calculations.
These similarity calculations can be based on Euclidean distance, cosine similarity, Manhattan distance, and so on.
Essentially, it compares the query vector to all the vectors in its storage to find ones most similar to the query.
The result of the similarity search is the retrieval of the most relevant content that matches the query.
This output is depicted as the answer.
![[Pasted image 20250406125937.png]]

## Retrieval by similarity
Here, you can see the code for performing the similarity search.
The query can be any text you were interested in about the source data.
Then you called the previously constructed vector and perform the similarity search based on the search.
The search will return the top four most similar content from the vector database by default.
For example, here, the query is regarding email policy, and the search returns the content shown.
![[Pasted image 20250406130027.png]]

## Recap
- You can store the embeddings from your data sources using a vector store.
- A vector database retrieves information based on queries using similarity search, enabling relevant answers.
- Chroma DB is a vector store that saves embeddings along with metadata. It is a powerful tool for semantic search.
- To construct the Chroma DB vector database using LangChain, you import the Chroma class from LangChain vector stores and called the chunks and embedding model. Then it can form a vector database automatically.
- A similarity search process starts with a query, which the embedding model converts into a numerical format.
- The vector database compares the query vector to all the vectors in its storage to find the ones most similar to the query.