# Transformers for Classification: Encoder

Using a traditional neural network for document analysis can result in the loss of contextual relationships between words.
![[Pasted image 20250317002251.png|400]]

However by integrating transformer attention layers the entire sequence of words can be processed collectively.
This approach allows the network to classify the document while retaining contextual information.
![[Pasted image 20250317002330.png|400]]

Let's look at how transformers are utilized for document classification.
The iterator is created from the training split of the AG_NEWS dataset using torch text.
The output consists of text representing news articles along with their corresponding labels indicating their categories.
```python
train_iter= AG_NEWS(split="train")
y,text= next(iter(train_iter ))
print(y,text)
```
![[Pasted image 20250317002929.png|400]]

You can assign the appropriate non numerical category headlines to the labels business for the first two sentences and science and technology for the last sentence.
```python
ag_news_label = {1: "World", 2: "Sports", 3: "Business", 4: "Sci/Tec"}
ag_news_label[y]
```

For the AG_NEWS dataset, you create iterators for both training and test splits, employ PyTorch data loader and allocate 95% of the training set for training with 5% reserved for validation
```python
# Split the dataset into training and testing iterators.
train_iter, test_iter = AG_NEWS()

# Convert the training and testing iterators to map-style datasets.
train_dataset = to_map_style_dataset(train_iter)
test_dataset = to_map_style_dataset(test_iter)

# Determine the number of samples to be used for training and validation (5% for validation).
num_train = int(len(train_dataset) * 0.95)

# Randomly split the training dataset into training and validation datasets using `random_split`.
# The training dataset will contain 95% of the samples, and the validation dataset will contain the remaining 5%.
split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])
```

You set up a tokenizer for English text, generate tokens from a dataset and construct a vocabulary.
```python
tokenizer = get_tokenizer("basic_english")

def yield_tokens(data_iter):
    for  _,text in data_iter:
        yield tokenizer(text)

vocab = build_vocab_from_iterator(yield_tokens(dataset), specials=["<unk>"])
vocab.set_default_index(vocab["<unk>"])
```

You can then design a custom collate function to handle the unique requirements of the dataset for sequence classification.
The primary distinction from the previous classification tasks is that the output now consists of a sequence index.
Additionally, to accommodate sequences of varying lengths, you apply zero padding to standardize the results.
```python
from torch.nn.utils.rnn import pad_sequence

def collate_batch(batch):
    label_list, text_list = [], []
    for _label, _text in batch:
        label_list.append(label_pipeline(_label))
        text_list.append(torch.tensor(text_pipeline(_text), dtype=torch.int64))


    label_list = torch.tensor(label_list, dtype=torch.int64)
    text_list = pad_sequence(text_list, batch_first=True)


    return label_list.to(device), text_list.to(device)
```

You can create a data loader for the training, validation and testing sets.
```python
BATCH_SIZE = 64

train_dataloader = DataLoader(
    split_train_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch
)
valid_dataloader = DataLoader(
    split_valid_, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch
)
test_dataloader = DataLoader(
    test_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch
)
```

When you examine the samples, you can see that the labels are integers and their count matches the batch size.
```python
label,seqence=next(iter(valid_dataloader))
# tensor([2, 0, ...])
```

The variable sequence is a tensor holding indexed sequences in transformer based models unlike traditional neural networks, the tensors first dimension represents the sequence and the second dimension represents the batch.
![[Pasted image 20250317003444.png|300]]

## Creating the model in PyTorch.
You will delve into the encoders constructor used for classification tasks and unpack the associated parameters.
The focus will be on the aspects pertinent to the transformer architecture and the sequential processing of input layers.
The embedding layer is instantiated via `nn.embedding`.
This layer maps tokens from the vocabulary sized vocab size into the dense vectors of a specified dimension embedding_dim, to observe the encoder in action you can invoke the forward function.
```python
class Net(nn.Module):
    def __init__(
        self,
        vocab_size,
        num_class,
        embedding_dim=100,
        nhead=5,
        num_layers=6):
        
        super().__init__()
        self.emb = nn.Embedding(vocab_size, embedding_dim)
        self.pos_encoder = PositionalEncoding(
            d_model=embedding_dim,
            dropout=dropout,
            vocab_size=vocab_size,
        )
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embedding_dim,
            nhead=nhead,
        )
        self.transformer_encoder = nn.TransformerEncoder(
            encoder_layer,
            num_layers=num_layers,
        )
        self.classifier = nn.Linear(embedding_dim, num_class)
        self.d_model = embedding_dim

    def forward(self, x):
        x = self.emb(x) * math.sqrt(self.d_model)
        x = self.pos_encoder(x)
        x = self.transformer_encoder(x)
        x = x.mean(dim=1)
        x = self.classifier(x)

        return x
```

Let's explore how the function processes each layer of the input through the variable x.
The text I like football is tokenized and indexed as 0, 317, 341.
![[Pasted image 20250317003847.png|300]]

These indices are inputs to an embedding layer that converts each token into its corresponding high dimensional representation.
Specifically, the embedding layer maps each index to a unique vector in an embedding space, where the first dimension corresponds to the sequence length, which is the number of tokens and the second dimension represents the embedding size.
The positional encoding module pos_encoder embeds sequence order into word embeddings.
It's applied to the embeddings x to add this temporal context.
![[Pasted image 20250317003933.png|400]]

These tensor values have the same dimensions as the input embeddings because they are eventually added together.
By combining these two, the model comprehends both the semantic and their positions in the sequence.
The encoder consists of multiple layers `nn.transformer` encoder layer, each configured with parameters.
These layers are then stacked on top of each other using `nn.transformer` encoder with the specified number of layers, num layers and the number of heads n heads.
After adding positional encodings, you apply the transformer encoder layers to the enhanced embeddings, allowing the model to capture the sequence's context.
![[Pasted image 20250317004043.png|400]]

The encoder generates the same number of embeddings with the same dimensions.
![[Pasted image 20250317004152.png|400]]
These tokens now contain context information, you can then calculate the mean along dimension zero and reduce the dimension size.
![[Pasted image 20250317004213.png|300]]

However, you can use the mean to classify the tasks.
The model features a linear layer `nn.linear`, which acts as the classifier.
It's set up with an input size equal to the embedding dimension and an output size that matches the number of classes.

You can then aggregate the embeddings from the encoder's output, typically by taking the mean before applying this linear layer.
The classifier layer predicts the label to which the input text belongs, determining the categorical classification of the given sequence.
![[Pasted image 20250317004358.png|400]]

Now let's look at the forward method to create a model.
In the model's forward method, the input x is used as an input to the embedding layer and scaled by the square root of the model dimension to stabilize gradients, preparing x for subsequent layers.
The dimensions are a little different from a neural network.
```python
class Net(nn.Module):
    # ...

    def forward(self, x):
        x = self.emb(x) * math.sqrt(self.d_model)
        x = self.pos_encoder(x)
        x = self.transformer_encoder(x)
        x = x.mean(dim=1)
        x = self.classifier(x)

        return x
```

The input tensor x represents a sequence length 67 of tokens organized in batches of 64 samples.
This is used as an input to the embedding layer.
The output of the embedding layer is 67 by 64.
The final dimension is the embedding dimension of 100.
![[Pasted image 20250317004547.png|300]]

The input tensor x undergoes positional encoding through the self.pos_encoder of x operation.
The positional encoding does not change the dimension.
![[Pasted image 20250317004651.png|300]]

The input tensor x undergoes transformation through the transformer encoder of x operation.
The output dimension of the tensor produced by the transformer encoder is the same as that of the input it receives.
The number of endings is equal to the number of sequence tokens.
These are called contextual embeddings, which have more information about the context.
![[Pasted image 20250317004718.png|300]]

The tensor x is averaged along dimension 0 with x mean of dim equal to 0 to compile the sequences information into a single embedding.
For the batch of 64 you can condense it into a single 100 dimensional vector, akin to having a data set with 64 instances each with 100 features.
The tensor x is processed by a linear classifier within the forward method representing the model's prediction for the given input sequence.
The classifier model outputs 64 label predictions for each sample in the batch size.
![[Pasted image 20250317004833.png|400]]

Create a model
```python
model = Net(vocab_size=vocab_size, num_class=4).to(device)
model
```
## Training the model.
The model's learning configuration includes a learning rate of 0.1 for stochastic gradient descent and cross entropy loss for multi class classification, SGD is the chosen optimizer with a step scheduler that decreases the learning rate by a factor of 0.1 after each epoch.
For tracking progress, cumulative loss list and accuracy epoch are initialized to record cumulative losses and epoch accuracies, respectively.
Additionally, accuracy old is used to retain the accuracy from the previous iteration.
```python
LR=0.1

criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=LR)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)

EPOCHS = 10
cum_loss_list=[]
acc_epoch=[]
acc_old=0
```

The training process for the model is the same as a standard classification problem despite the transformers typical use for sequence to sequence tasks.
```python
for epoch in tqdm(range(1, EPOCHS + 1)):
    model.train()
    cum_loss=0
    for idx, (label, text) in enumerate(train_dataloader):
        optimizer.zero_grad()
        label, text=label.to(device), text.to(device)

        predicted_label = model(text)
        loss = criterion(predicted_label, label)
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)
        optimizer.step()
        cum_loss+=loss.item()
    print("Loss",cum_loss)

    cum_loss_list.append(cum_loss)
    accu_val = evaluate(valid_dataloader)
    acc_epoch.append(accu_val)

    if accu_val > acc_old:
      acc_old= accu_val
      torch.save(model.state_dict(), 'my_model.pth')

save_list_to_file(lst=cum_loss_list, filename="loss.pkl")
save_list_to_file(lst=acc_epoch, filename="acc.pkl")
```

The plot displays the loss and accuracy of the model trained over ten epochs.
You will see that when the training loss decreases, the validation accuracy increases.
For larger datasets, transformers typically perform better than neural networks.
![[Pasted image 20250317005506.png|400]]

## Recap 
- You could retain context while classifying text by integrating transformer attention layers.
- To create the text pipeline:
	- Create iterators, allocate training set, generate tokens and construct a vocabulary.
	- Design a custom collate function, apply padding and create a data loader
- To create the model:
	- Instantiate the embedding layer, add positional encoding and apply the transformer encoder layers.
	- Use the classifier layer to predict the label to which the input text belongs.
- To train the model:
	- Use the same process as a standard classification problem.